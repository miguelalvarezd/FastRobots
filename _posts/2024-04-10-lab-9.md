---
layout: post
title:  "Lab 9 - Mapping"
author: miguel
#categories: [ Jekyll, tutorial ]
#tags: [red, yellow]
image: assets/images/lab9.png
description: "The objective of Lab 9 is to map a static room with the robot."
featured: false
hidden: true
#rating: 4.5
---
The objective of Lab 9 is to map a static room with the robot.

### Prelab

The prelab of this lab consists of reviewing the lecture on transformation matrices, as they will be useful later on. 

### Tasks

The goal of this lab is to map certain room. To do this, the robot will rotate on its axis in small angles, and obtain the distance to the wall at that angle. The way I chose to do this was with Orientation Control, as it has proven to be an efective method in previous labs. The room the robot will map is shown below. The robot will be placed at every point marked in the floor and get readings from there.

|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/room_front.jpg" alt="Room, front view.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/room_back.jpg" alt="Room, back view.">|


#### 1. Orientation Control

The first step of the lab is to set up the Orientation Control, so that the robot reads a distance every certain angle. The Controller from <a href="https://miguelalvarezd.github.io/FastRobots/lab-6/" target="_blank">Lab 6</a> was reused, with some modifications.

- Aside from Kp, Ki and Kd, the number of readings (`nReadings`) and the angle between each reading (`angle_to_turn`) were also set via Bluetooth.

- Whenever the error is 0 for some loop cycles, the controller will reset the angle back to 0 (therefore reducing the drift), read the distance to the wall, and perform a new turn.

```
if(mapp.last_n_error_0 >= 5){
  //Read new values from ToF...

  //Save angle and values of distance...

  mapp.j++; //Update counter of readings

  //Now, reset the angle to 0. The Set Point is the same as angle_to_turn, so the robot will turn again
  mapp.yaw = 0;
}
```

- Once we have done `nReadings`, stop the test.

```
if(mapp.j > mapp.nReadings){
  mapp.run_test = false;
  mapp.pid = 0;
  brake();
  Serial.println("Test ended. Brake");
}
```

With this controller we can make the robot turn on-axis, and read the distance at every turn, as show in the video below. To have more readings, and therefore create a more reliable map, both ToF sensors were used (One points to the front, and the other is positioned 90 degrees to the right. See <a href="https://miguelalvarezd.github.io/FastRobots/lab-4/#:~:text=was%20broken.%20The-,new%20layout,-of%20the%20robot" target="_blank">layout from Lab 4</a>).

<iframe width="640" height="360" frameborder="0" allowfullscreen
src="https://www.youtube.com/embed/jJ3lj4UVngA">
</iframe>

#### 2. Map Readings

The robot was placed on each of the points in the floor, in order to map the room. For each point, 45 readings were taken, at 8 degrees of separation each (in total, a full 360 degree rotation). The controller parameters used were **Kp = 8.5**, **Ki = 0.0**, and **Kd = 0.95**. The result from each reading is shown below. The coordinates of each point are measured in feet, while the distances in the plots are in millimeters. For each point, three plots are provided: one which shows the ToF readings for every angle, a second one representing the readings in polar coordinates, and the last one representing the readings in the global map (after a transformation, explained in next section).

**1. Point (0,0)**

|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/tof1.png" alt="ToF Readings, Point 1.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/polar1.png" alt="Polar Coordinates, Point 1.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/global1.png" alt="Global Map, Point 1.">|

**2. Point (5,-3)**

|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/tof2.png" alt="ToF Readings, Point 2.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/polar2.png" alt="Polar Coordinates, Point 2.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/global2.png" alt="Global Map, Point 2.">|

**3. Point (-3,-2)**

|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/tof3.png" alt="ToF Readings, Point 3.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/polar3.png" alt="Polar Coordinates, Point 3.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/global3.png" alt="Global Map, Point 3.">|

**4. Point (5,3)**

|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/tof4.png" alt="ToF Readings, Point 4.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/polar4.png" alt="Polar Coordinates, Point 4.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/global4.png" alt="Global Map, Point 4.">|

**5. Point (0,3)**

|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/tof5.png" alt="ToF Readings, Point 5.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/polar5.png" alt="Polar Coordinates, Point 5.">|<img class= "img_post" src="{{ site.baseurl }}/assets/images/lab9/global5.png" alt="Global Map, Point 5.">|

#### 3. Transformation Matrices

The readings obtained from the tests above provide an angle and a distance for every turn. When reading, I considered the front ToF sensor to be pointing in the positive X direction, and the side one in the negative Y direction. I order to merge the readings and plot them together, we need to transform the points into the same reference system. We can do this with Transformation Matrices.

For every case, the reading is centered on the ToF sensor. Additionally, each reading is taken at a different angle, and from a different point in the map. Note that the angle for the side ToF sensor has been modified when sending the data by subtracting 90 degrees to the robot's yaw, so it reflects the real angle for that reading. Therefore, for each readings we have:

- Translation from the center of the robot to each ToF sensor. The front ToF sensor is 69.85mm from the center, in the X direction, while the side sensor is -34.925mm from the center, in the Y direction. We just have to add these distances to each point.

$$
Tr1=\left(\begin{array}{cc} 
69.85 \\
0
\end{array}\right); Tr2=
\left(\begin{array}{cc} 
0\\ 
-34.925
\end{array}\right)
$$ 

- Rotation on the robot's axis. For every point, the robot has rotated a certain known angle. The transformation matrix in this case is:

$$
T=\left(\begin{array}{cc} 
cos(\theta) \\
-sin(\theta)
\end{array}\right)=
\left(\begin{array}{cc} 
sin(\theta)\\ 
cos(\theta)
\end{array}\right)
$$ 